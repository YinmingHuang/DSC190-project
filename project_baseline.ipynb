{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf507a3-0866-4bf8-a3f5-cbfa949cf4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Initialize lists\n",
    "queries = []\n",
    "passages = []\n",
    "query_ids = []\n",
    "passage_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9133c5db-ebe1-4093-9466-44d8040824c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in dataset: 21223\n",
      "{'qid': 0, 'query': \"I need filters that effectively trap dust and improve the air quality in my home. It's surprising how much dust they can collect in just a few months.\", 'item_id': 'B0C5QYYHTJ', 'user_id': 'AGREO2G3GTRNYOJK4CIQV2DTZLSQ', 'ori_rating': 5, 'ori_review': 'These filters work I could not believe the amount of dust in the old filter when it was replaced after 3 months.  These really trap the dust and make my home a much healthier place.'}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('McAuley-Lab/Amazon-C4', split='test')\n",
    "\n",
    "print(f\"Total entries in dataset: {len(dataset)}\")\n",
    "print(dataset[0])  # View the first entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff46c39-51fc-41b7-8ff1-6d1a5c988c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items in item_dict: 1058417\n"
     ]
    }
   ],
   "source": [
    "# Download the item metadata file\n",
    "filepath = hf_hub_download(\n",
    "    repo_id='McAuley-Lab/Amazon-C4',\n",
    "    filename='sampled_item_metadata_1M.jsonl',\n",
    "    repo_type='dataset'\n",
    ")\n",
    "\n",
    "# Build a dictionary mapping item_id to metadata\n",
    "item_dict = {}\n",
    "\n",
    "with open(filepath, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        item = json.loads(line.strip())\n",
    "        item_id = item.get('item_id')\n",
    "        metadata = item.get('metadata')\n",
    "        if item_id and metadata:\n",
    "            item_dict[item_id] = metadata\n",
    "\n",
    "print(f\"Total items in item_dict: {len(item_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48928ba-01d1-488b-b08b-de3bb78a541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    query_text = data.get('query', '').strip()\n",
    "    item_id = data.get('item_id', '').strip()\n",
    "    qid = data.get('qid', None)\n",
    "    \n",
    "    # Get the passage text from item_dict using item_id\n",
    "    passage_text = item_dict.get(item_id, None)\n",
    "    \n",
    "    # Check if both query and passage_text are available\n",
    "    if query_text and passage_text:\n",
    "        # Append prefixed texts to respective lists\n",
    "        queries.append('query: ' + query_text)\n",
    "        passages.append('passage: ' + passage_text)\n",
    "        query_ids.append(qid)\n",
    "        passage_ids.append(item_id)\n",
    "    else:\n",
    "        # Handle missing data (optional)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09692070-0d1b-4030-b3e8-6595d88c79c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"query: I need filters that effectively trap dust and improve the air quality in my home. It's surprising how much dust they can collect in just a few months.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0829a9d-3be3-45d7-be0f-36fcbc4da0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'passage: Flintar Core 300 True HEPA Replacement Filters, Compatible with LEVOIT Core 300, Core 300S VortexAir Air Purifier, 3-in-1 H13 Grade True HEPA Filter Replacement, Core 300-RF, 2-Pack. Flintar Premium high-efficiency H13 Grade True HEPA Replacement Filter is made in Taiwan and is fully compatible with LEVOIT Core 300 and Core 300S VortexAir Air Purifier. This True HEPA Filtration System includes:   - Fine Pre-Filter: Traps larger particles in the air like dust, hairs, pet fur, lint, and more - H13 Grade True HEPA Filter: Captures 99.97% of harmful airborne particles down to 0.3 microns in size   - High-Efficiency Activated Carbon Filter: Absorbs household odors from pets, cooking, smoke, wildfire, and harmful VOC’s Using Flintar premium high-efficiency air purifier filters and replacing the filters regularly will help optimize air cleaning performance. Replace your HEPA Filter every 6 months for optimal performance. Fully compatible with LEVOIT Cor 300 and Core 300S VortexAir Air Purifier.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84403fa2-4630-4c67-b4b5-a5572d76b818",
   "metadata": {},
   "source": [
    "# Baseline: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdaedca0-426b-4679-b556-bc87f7c6b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 42.34%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Step 1: Preprocess the data\n",
    "clean_queries = [q.replace('query: ', '') for q in queries]\n",
    "clean_passages = [p.replace('passage: ', '') for p in passages]\n",
    "\n",
    "# Step 2: Vectorize the passages\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(clean_passages)\n",
    "passage_tfidf = vectorizer.transform(clean_passages)\n",
    "\n",
    "# Step 3: Vectorize the queries\n",
    "query_tfidf = vectorizer.transform(clean_queries)\n",
    "\n",
    "# Step 4: Compute cosine similarity\n",
    "# Since TF-IDF vectors are L2-normalized by default, the dot product yields cosine similarity\n",
    "cosine_sim_matrix = query_tfidf.dot(passage_tfidf.T)\n",
    "\n",
    "# Step 5 and 6: Retrieve top 200 passages and calculate accuracy\n",
    "accuracy_count = 0\n",
    "total_queries = len(queries)\n",
    "\n",
    "for i in range(total_queries):\n",
    "    # Get similarity scores for query i\n",
    "    sim_scores = cosine_sim_matrix[i].toarray().flatten()\n",
    "    # Retrieve indices of top 200 passages\n",
    "    top_200_indices = np.argsort(-sim_scores)[:200]\n",
    "    # Check if the correct passage is among the top 200\n",
    "    if i in top_200_indices:\n",
    "        accuracy_count += 1\n",
    "\n",
    "# Step 7: Calculate accuracy\n",
    "accuracy = accuracy_count / total_queries\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c00d1-5def-4d65-b8ea-a54df7055b39",
   "metadata": {},
   "source": [
    "# End of Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf5d920b-4a2a-4565-81ac-0e6f249ae61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique passages: 20367\n",
      "Total unique queries: 21222\n"
     ]
    }
   ],
   "source": [
    "# Get unique passages\n",
    "unique_passages = list(set(passages))\n",
    "print(f\"Total unique passages: {len(unique_passages)}\")\n",
    "\n",
    "# Get unique queries\n",
    "unique_queries = list(set(queries))\n",
    "print(f\"Total unique queries: {len(unique_queries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b17c1076-d20f-4f4c-a1b1-8fe54ee5de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# # Create a dictionary to map each unique query to its associated unique passage(s)\n",
    "# query_to_passages = defaultdict(set)\n",
    "# for q, p in zip(queries, passages):\n",
    "#     query_to_passages[q].add(p)\n",
    "\n",
    "# # Create a list mapping each unique query to its relevant unique passage index\n",
    "# query_to_unique_p_idx = []\n",
    "# for q in unique_queries:\n",
    "#     passages_set = query_to_passages.get(q, set())\n",
    "#     if len(passages_set) == 1:\n",
    "#         # If there's only one passage for the query\n",
    "#         p = next(iter(passages_set))\n",
    "#         p_idx = unique_passages.index(p)  # Get the index in unique_passages\n",
    "#         query_to_unique_p_idx.append(p_idx)\n",
    "#     elif len(passages_set) > 1:\n",
    "#         # If multiple passages are associated, decide how to handle\n",
    "#         # For simplicity, choose the first one\n",
    "#         p = next(iter(passages_set))\n",
    "#         p_idx = unique_passages.index(p)\n",
    "#         query_to_unique_p_idx.append(p_idx)\n",
    "#     else:\n",
    "#         # If no passage is found for the query\n",
    "#         query_to_unique_p_idx.append(-1)\n",
    "\n",
    "# # Check for queries without a corresponding passage\n",
    "# num_missing = query_to_unique_p_idx.count(-1)\n",
    "# print(f\"Number of queries with no passage: {num_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a783c5-452d-476f-820b-1ffd7907c297",
   "metadata": {},
   "source": [
    "# e5-large model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0ea48c-2acd-4f97-a43a-7bcdafca290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:3\n",
      "Number of Queries: 21223\n",
      "Number of Passages: 21223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Passages: 100%|██████████████████████████████████████████████████████████████| 332/332 [08:20<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage Embeddings Shape: (21223, 1024)\n",
      "Number of Passages Indexed: 21223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Queries: 100%|███████████████████████████████████████████████████████████████| 332/332 [02:52<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Embeddings Shape: (21223, 1024)\n",
      "Distances Shape: (21223, 5)\n",
      "Indices Shape: (21223, 5)\n",
      "\n",
      "Query 1: I need filters that effectively trap dust and improve the air quality in my home. It's surprising how much dust they can collect in just a few months.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8458\n",
      "    Passage: 30x60 (cut-to-fit) Filtrete Hammock Filter by 3M. This 3M Filtrete Filter is a Cut-to-Fit. It is a great choice for people who want to improve their Indoor Air Quality and help reduce allergens and microscopic particles from the air in their homes including nuisance household dust.\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8435\n",
      "    Passage: Dreo Air Purifiers Macro Pro, True HEPA Filter, Up to 1358ft² Coverage, 20dB Low Noise, PM2.5 Sensor, 6 Modes, 360 Filtration Cleaner Remove 99.985% Dust Smoke Pollen, Black. .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8429\n",
      "    Passage: Dayette HEPA Air Purifiers for Home Large Room, CADR 300+m³/h Up to 1290ft² with Air Quality Sensor, H13 True HEPA Filter Remove 99.97% of Dust, Mold, Allergies, Odor, Pets Dander, Smoke, Pollen. .\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8383\n",
      "    Passage: POMORON MJ002H 4-in-1 Air Purifiers for Home, H13 True Hepa Filter, Air Ionizer Negative Ion Generator and UV, Filter 0.3 Microns Particles Such As Smoke Dander Air Cleaner for Bedroom Office, Black. .\n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8381\n",
      "    Passage: Reusable Respirator, MYGCCA Dust Respirator with Filter 2091 for Painting, Epoxy Resin, Asbestos, Particulate, Sanding, Machine Polishing and Other Work. .\n",
      "\n",
      "\n",
      "Query 2: I need to find a protein that is super healthy and worth the high price. I've been using this protein for a few years and have no complaints about it.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8424\n",
      "    Passage: 2 lb Egg White Protein Powder by Source Nutrition - 25 Grams Protein, Build Lean Muscle, Dairy Free - Milk Chocolate. .\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8375\n",
      "    Passage: Vital Proteins Collagen Peptides Powder, with Hyaluronic Acid and Vitamin C, Unflavored, 9.33 Ounce. .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8375\n",
      "    Passage: Vital Proteins Collagen Peptides Powder, with Hyaluronic Acid and Vitamin C, Unflavored, 9.33 Ounce. .\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8375\n",
      "    Passage: Vital Proteins Collagen Peptides Powder, with Hyaluronic Acid and Vitamin C, Unflavored, 9.33 Ounce. .\n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8370\n",
      "    Passage: MuscleMeds Carnivor Beef Protein Isolate Powder, Muscle Building, Recovery, Lactose Free, Sugar Free, Fat, Free, 23g Protein, Rocket Pop, 56 Servings. CARNIVOR Beef Protein Isolate delivers all the muscle building power of beef with greater amino acid levels than other protein sources used in supplements, including whey, soy, milk and egg. CARNIVOR Beef Protein Isolate (BPI) is even 350% more concentrated in anabolic muscle building aminos than a prime sirloin steak! And it’s sugar free, fat free, lactose free or cholesterol free! Plus, CARNIVOR is one of the most delicious protein shakes you’ll ever try!. World's first and #1 selling beef protein. 23g of muscle building USDA approved beef protein, without the unwanted fat or cholesterol. Easier on the stomach - lactose, sugar, dairy and gluten free. More concentrated in amino acids than WHEY protein. Features a clinically tested muscle building beef protein that is time tested with millions of bottles sold. 350% More Concentrated Than Steak & More Concentrated Than Whey.\n",
      "\n",
      "\n",
      "Query 3: I need a pillow that helps keep my nasal pillow in place while I sleep with my CPAP machine. It should provide the neck support I need and give me a comfortable night's sleep.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8841\n",
      "    Passage: Memory Foam Pillow for CPAP Side Sleeper, IKSTAR 2.0 CPAP Pillow for Neck Support Relief Neck Pain Suit for All CPAP Masks User, Nasal Pillows for Side Back Sleepers - Reduce Air Leaks & Mask Pressure. .\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8637\n",
      "    Passage: Memory Foam Pillows, Height-Adjustable ANLIKE Pillow, Orthopedic Cervical Neck Support Pillow, Orthopedic Cervical Neck Support Pillow. .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8591\n",
      "    Passage: Memory Foam Pillows, Adjustable Bed Pillow for Sleeping, Ergonomic Cervical Pillow Neck Support Pillow for Side Back Stomach Sleeper, Orthopedic Contour Pillow for Neck and Shoulder Pain. .\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8585\n",
      "    Passage: ZAMAT Adjustable Cervical Memory Foam Pillow, Odorless Neck Pillows for Pain Relief, Orthopedic Contour Pillows for Sleeping with Cooling Pillowcase, Bed Support Pillow for Side, Back, Stomach Sleeper. .\n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8585\n",
      "    Passage: ZAMAT Adjustable Cervical Memory Foam Pillow, Odorless Neck Pillows for Pain Relief, Orthopedic Contour Pillows for Sleeping with Cooling Pillowcase, Bed Support Pillow for Side, Back, Stomach Sleeper. .\n",
      "\n",
      "\n",
      "Query 4: I need a memory stick that is excellent and exceeds expectations. It should be compatible with both Android and Apple devices. I want to be able to easily store and download files from my laptop to my phone in seconds.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8576\n",
      "    Passage: Flash Drive 128GB for iPhone Thumb Drives USB Memory Stick High Speed Jump Drive,Photo Stick External Storage for iPhone/iPad/Android/PC(Blue). .\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8571\n",
      "    Passage: Flash Drive for iPhone 256GB, AUAMOZ USB iOS Memory Stick Photo Stick External Storage Thumb Drive for iPhone iPad Android Computer (Light Blue). .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8476\n",
      "    Passage: SCICNCE 1TB Photo Stick iPhone Flash Drive, for iPhone USB Memory Stick Thumb Drives USB Stick External Storage Compatible with iPhone iPad Android PC (Dark Grey). .\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8475\n",
      "    Passage: Sunany Flash Drive 128GB, USB Memory Stick External Storage Thumb Drive for Phone, Pad, Android, PC and More Devices (Red). .\n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8475\n",
      "    Passage: Sunany Flash Drive 128GB, USB Memory Stick External Storage Thumb Drive for Phone, Pad, Android, PC and More Devices (Red). .\n",
      "\n",
      "\n",
      "Query 5: I want to buy something that my children will love. My son saw a video and asked me to get it for him. He and his little sisters have been drawing every day since we got it.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8258\n",
      "    Passage: ORSEN LCD Writing Tablet 10 Inch, Colorful Doodle Board Drawing Pad for Kids, Drawing Board Writing Board Drawing Tablet, Educational Christmas Boys Toys Gifts for 3 4 5 6 Year Old Boys, Girls. .\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8231\n",
      "    Passage: HCFJEH Magnetic Drawing Board for Toddlers 1-3, Color Erasable Doodle Writing Pad, Learning Painting Sketch Pad, Best Birthday Easter Christmas Halloween Kids Toy Gifts for Boys and Girls(Blue). .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8219\n",
      "    Passage: The Boys' Doodle Book: Amazing Picture to Complete and Create. .\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8193\n",
      "    Passage: Toy. .\n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8151\n",
      "    Passage: ORSEN Colorful 8.5 Inch LCD Writing Tablet for Kids, Electronic Sketch Drawing Pad Doodle Board, Toddler Travel Learning Educational Toys Activity Games Birthday Gifts for 2 3 4 5 6 7 8 Year Old Girls. .\n",
      "\n",
      "Recall@5: 33.20%\n",
      "Mean Reciprocal Rank (MRR): 0.2296\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "# Set the device (adjust 'cuda:1' based on your GPU setup)\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to(device)\n",
    "\n",
    "# Assuming 'queries' and 'passages' lists are already defined and populated\n",
    "# Example:\n",
    "# queries = ['query: How much protein should a female eat', 'query: 南瓜的家常做法', ...]  # 21,223 entries\n",
    "# passages = ['passage: As a general guideline...', 'passage: 1.清炒南瓜丝...', ...]  # 21,223 entries\n",
    "\n",
    "print(f\"Number of Queries: {len(queries)}\")\n",
    "print(f\"Number of Passages: {len(passages)}\")\n",
    "\n",
    "# Step 1: Encode and Index Passages\n",
    "batch_size = 64\n",
    "passage_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(passages), batch_size), desc=\"Encoding Passages\"):\n",
    "    batch_passages = passages[i:i+batch_size]\n",
    "    batch_dict = tokenizer(\n",
    "        batch_passages,\n",
    "        max_length=512,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "    \n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "    passage_embeddings.append(embeddings)\n",
    "\n",
    "passage_embeddings = np.vstack(passage_embeddings)\n",
    "print(f\"Passage Embeddings Shape: {passage_embeddings.shape}\")\n",
    "\n",
    "embedding_dim = passage_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "index.add(passage_embeddings)\n",
    "print(f\"Number of Passages Indexed: {index.ntotal}\")\n",
    "\n",
    "# Step 2: Encode Queries\n",
    "query_batch_size = 64\n",
    "query_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(queries), query_batch_size), desc=\"Encoding Queries\"):\n",
    "    batch_queries = queries[i:i+query_batch_size]\n",
    "    batch_dict = tokenizer(\n",
    "        batch_queries,\n",
    "        max_length=512,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "    \n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "    query_embeddings.append(embeddings)\n",
    "\n",
    "query_embeddings = np.vstack(query_embeddings)\n",
    "print(f\"Query Embeddings Shape: {query_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5eeb89a-a2f1-4971-8260-40f021f0befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n",
      "Number of Queries: 21223\n",
      "Number of Passages: 21223\n",
      "Total unique passages: 20367\n",
      "Total unique queries: 21222\n",
      "Number of queries with no passage: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Passages: 100%|██████████████████████████████████████████████████████████████| 319/319 [10:20<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage Embeddings Shape: (20367, 1024)\n",
      "Number of Passages Indexed: 20367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Queries: 100%|███████████████████████████████████████████████████████████████| 332/332 [06:28<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Embeddings Shape: (21222, 1024)\n",
      "Distances Shape: (21222, 5)\n",
      "Indices Shape: (21222, 5)\n",
      "Recall@5: 34.68%\n",
      "Mean Reciprocal Rank (MRR): 0.2371\n",
      "\n",
      "Query 1: I'm looking for supplements that can help with my dog's anxiety, especially during car rides. I want something that will not make her sedated but instead keep her calm and relaxed. It would be great if the supplements can make the entire experience stress-free for both my dog and myself.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8574\n",
      "    Passage: NaturVet Quiet Moments Calming Aid Cat Supplement Plus Melatonin – Helps Reduce Stress in Cats – for Pet Storm Anxiety, Motion Sickness, Grooming, Separation, Travel – 50 Ct. Soft Chews. .\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8553\n",
      "    Passage: Hemp Calming Chews for Dogs with Anxiety and Stress - Dog Calming Treats - Dog Anxiety Relief - Storms, Barking, Separation - Valerian - Hemp Oil - Calming Treats for Dogs - Made in USA. .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8552\n",
      "    Passage: PREMIUM CARE Hemp Calming Chews for Dogs, Made in USA, Helps with Dog Anxiety, Separation, Barking, Stress Relief, 9.3 oz (264g), 120 count. .\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8493\n",
      "    Passage: Spotclean Pro w/Anti Bac + Pet Pro Oxy. .\n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8469\n",
      "    Passage: Bissell SpotClean Pet Pro + Pro Pet Formula. .\n",
      "\n",
      "\n",
      "Query 2: I am looking for an author who writes thrilling books that can keep me awake during a long trip. I want a set of books that gets better with each one I read and has great characters.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8397\n",
      "    Passage: Devil's Hour: Zero Hour Series, Book 2. .\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8374\n",
      "    Passage: Towers of Heaven: A LitRPG Adventure (Book 3). .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8364\n",
      "    Passage: The Newton Cipher (Trina Piper Thrillers). .\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8354\n",
      "    Passage: Starfall: A LitRPG Adventure (Tower of Somnus Book 3). .\n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8325\n",
      "    Passage: Swept Away: A Time Travel Romance (The Swept Away Saga Book 1). Review The BEST book I've read THIS YEAR! ~Lacey Weatherford, #1 International and USA TODAY Bestselling author of Crush , Allure , and Of Witches and Warlocks.  Swept Away is the perfectly titled action-packed, swoon filled story by Kamery Solomon! From the first page to the heart racing last words, Swept Away took me on a swash buckling adventure--one that left me desperately wishing for a Tristan O'Rourke of my own. Watch out, peeps . . . this is pure GOLD . . . a treasure to devour! The hunt is over--pirates are the new addiction! ~Belinda Boring, #1 Genre and Top 100 Bestselling Author of The Mystic Wolves Amazing! The best way I can think to describe it is Pirates of the Caribbean meets Outlander! There is action, adventure, romance and so much more! You will not be disappointed! ~Heather Garrison, Amazon Customer Kamery Solomon never disappoints a reader in her ability to tell a great story. She has proven she's not a one trick pony and capable of writing across genres. Highly recommend reading any and all of her books. ~Lisa Markson, The Paranormal Bookworm This book has so many twists and turns that will keep you reading all night long. I love the characters and the mystery. The author does a fantastic job weaving every part in this story that will leave you wanting more. I highly recommend! ~Laura Collins, Amazon Customer I was pulled in right away and I did not want to put the book down, nor did I want the story to end . . . a must read! ~Holly Copper, Amazon Customer Marvelous, wonderful, awe-inspiring; these are just a few words to describe just a fraction of the awesomeness that is this book. ~Julie Engle, Amazon Customer This is a book I will read time and time again. ~Angie Angelich, Bookeepsie From the Author As you're reading, you may notice that the story of the Treasure Pit sounds somewhat familiar, and you would be right. Here's a small explanation of what inspired me-in part- to write Swept Away . InNova Scotia, Canada, there is an island called Oak Island. On this island is apit, called the Money Pit, that was discovered over two hundred years ago. Itwas seventeen ninety five when the three teenaged boys came across it and, withpirate treasure in mind, began to dig. That was the start of the world'slongest and least successful treasure hunt, continuing on today. Overthe years, hundreds of hopefuls have come to the island, dreaming of findingwhat's hidden at the bottom of the pit, including famous movie stars and aformer president. Until recently, nothing of value was ever found. The islandhas bankrupted everyone who's ever tried to solve the puzzle.  The myths and curses of Oak Isle in Swept Away are the same as the real lifeOak Island, including the prophecy that seven must die before anything can befound. At the time of this publication, six men had lost their lives in searchof the treasure.  Currently,two brothers--Rick and Marty Lagina--run the operation on the island. They founda gold coin in the swamp and became the first treasure hunters to turn upsomething of value. You can watch their efforts on the History Channel show, The Curse of Oak Island . While Swept Away is pure fiction, it excitesme to see just a little mystery left in the world, and the desire to discoverwhat all is out there. Several people do believe that the treasure of theKnights Templar is buried on the island, as well as the other theories broughtup in the book. Iencourage you to take a look at it for yourself--there is much, much more to thereal story than there is in Swept Away --anddecide for yourself what you think is really happening on Oak Island. About the Author Kamery is not the person who grew up dreaming of the day that she would clutch her very own novel to her chest, tears brimming over the rims of her eyes as she thought about how she'd written it herself, finally! In fact, anything remotely like that didn't even happen until she was actually holding her first book in her hand, amazed that she'd written it and wondering how on Earth she'd managed to do it when it hadn't ever occurred to her to write one until months before. Surprisingly, though, it was just what she never realized she loved doing.When starting out in life, Kamery had (and still has) big dreams to perform on Broadway. She loves music and acting very much, while she and dance have a love/hate relationship; she would love to do it and every form of dance decides it hates that about her, haha! The one constant she always had between the performing world and the book world were the stories, tales that transported her to other worlds and made her feel like she really could do anything. Finally, she decided she wanted to do that for someone else and sat down to write. It's been a few years since she held that first book, realizing that she really liked writing and wanted to do more, but the love that blossomed in that moment has only grown. Currently, Kamery works from home in the White Mountains of Arizona, while taking care of her two adorable kids, a girl and a boy, and talking her sweet husband Jake's ear off about the insane amount of characters in her head who are ready to fight to the death for a chance at their own novels. She also gets together with other authors in the family and they all gab together, making up The Royal Court of the Queens of Romance. It truly is a wonderful life! Read more.\n",
      "\n",
      "\n",
      "Query 3: I need a product of great quality that doesn't require any instructions. I bought it for my husband, who I want to join me in fishing. However, he would have preferred to receive some paper instructions on how to assemble it.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8259\n",
      "    Passage: Fishing Rod Reel Combo Portable Remind Fast Small Gear. .\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8249\n",
      "    Passage: . .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8235\n",
      "    Passage: Jason Markk On-The-Go Essentials. .\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8212\n",
      "    Passage: Wood Moisture Meter (Pinless-colors). .\n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8193\n",
      "    Passage: Flygo Men's Casual Multi-Pocket Outdoor Utility Fishing Photo Safari Work Travel Vest. .\n",
      "\n",
      "\n",
      "Query 4: I need a shelf that is solid and does what it's supposed to do. It should be perfect for the space I have.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8371\n",
      "    Passage: Oudtinx 2PCS Folding Shelf Brackets,Heavy Duty Triangle Shelf Bracket for Bench Table,Wall Mounted Standing Shelf Brackets for Saving Place,Multi Size 10 Silver. .\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8369\n",
      "    Passage: Floating Shelves - 24'' x 7.8'' x 1.5'' Solid Wood, Wall Shelf, Shelves for Wall Decor, Natural Rustic Farmhouse Solid Wood with Invisible Brackets, for Bathroom, Kitchen, Office, Living Room Decor. .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8350\n",
      "    Passage: Ubrand Moon Shelf Room Decor,Crystal Shelf, Reversible Wooden Essential Oil Shelf,Wall Mounted Floating Shelves,Burnt Color Crystal Jewelry Holder. .\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8342\n",
      "    Passage: HDANI 3-Tier Standing Shelf, Metal Storage Shelf Stand for Kitchen, Bedroom, Bathroom, Office(White)…. .\n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8332\n",
      "    Passage: Aeitc Storage Organizer 5-Cube (11.8inx11.8in) Narrow Cabinet Closet Storage Shelves Plastic Shelving for Bedroom, Living Room, Office, Transparent with Doors. .\n",
      "\n",
      "\n",
      "Query 5: I need to find a replacement spring for my installation. The one I currently have broke, so I want to order a new set with the correct spring. I don't want to buy the same product again, but instead, I'm looking for factory springs or reputable aftermarket springs from brands like Crane Cams or Competition Cams.\n",
      "Top Passages:\n",
      "  Rank 1:\n",
      "    Similarity Score: 0.8223\n",
      "    Passage: . .\n",
      "\n",
      "  Rank 2:\n",
      "    Similarity Score: 0.8204\n",
      "    Passage: Washer Door Boot Spring Clamp Assembly Wire Diaphragm Compatible with Samsung DC97-04973B Washing Machine. .\n",
      "\n",
      "  Rank 3:\n",
      "    Similarity Score: 0.8203\n",
      "    Passage: Samsung DA63-07512A Guard-Fre. This is an authorized aftermarket product. Fits with various Samsung brand models. It has a oem part # DA63-07512A.\n",
      "\n",
      "  Rank 4:\n",
      "    Similarity Score: 0.8202\n",
      "    Passage:  \n",
      "\n",
      "  Rank 5:\n",
      "    Similarity Score: 0.8191\n",
      "    Passage: YAMAKATO GX160 GX200 196cc 212cc Throttle Control Assembly Kit, Lever Arm and Plate Base, Governor Link Rod, Return Springs, Carburetor Spring Linkage for Honda Clones Predator 212 Ct200u etc. .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "# Set the device (adjust 'cuda:3' based on your GPU setup)\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to(device)\n",
    "\n",
    "# Assuming 'queries' and 'passages' lists are already defined and populated\n",
    "# Example:\n",
    "# queries = ['query: How much protein should a female eat', 'query: 南瓜的家常做法', ...]  # 21,223 entries\n",
    "# passages = ['passage: As a general guideline...', 'passage: 1.清炒南瓜丝...', ...]  # 21,223 entries\n",
    "\n",
    "print(f\"Number of Queries: {len(queries)}\")\n",
    "print(f\"Number of Passages: {len(passages)}\")\n",
    "\n",
    "# Step 1: Get unique passages and queries\n",
    "unique_passages = list(set(passages))\n",
    "print(f\"Total unique passages: {len(unique_passages)}\")  # 20,367\n",
    "\n",
    "unique_queries = list(set(queries))\n",
    "print(f\"Total unique queries: {len(unique_queries)}\")    # 21,222\n",
    "\n",
    "# Step 2: Create mapping from passage text to unique index\n",
    "passage_text_to_idx = {text: idx for idx, text in enumerate(unique_passages)}\n",
    "\n",
    "# Step 3: Create mapping from unique query to unique passage index\n",
    "query_to_passages = defaultdict(set)\n",
    "for q, p in zip(queries, passages):\n",
    "    query_to_passages[q].add(p)\n",
    "\n",
    "query_to_unique_p_idx = []\n",
    "for q in unique_queries:\n",
    "    passages_set = query_to_passages.get(q, set())\n",
    "    if len(passages_set) == 1:\n",
    "        p = next(iter(passages_set))\n",
    "        p_idx = passage_text_to_idx.get(p, -1)\n",
    "        query_to_unique_p_idx.append(p_idx)\n",
    "    elif len(passages_set) > 1:\n",
    "        # Choose the first passage if multiple are associated\n",
    "        p = next(iter(passages_set))\n",
    "        p_idx = passage_text_to_idx.get(p, -1)\n",
    "        query_to_unique_p_idx.append(p_idx)\n",
    "    else:\n",
    "        # No passage found\n",
    "        query_to_unique_p_idx.append(-1)\n",
    "\n",
    "# Check for queries without a corresponding passage\n",
    "num_missing = query_to_unique_p_idx.count(-1)\n",
    "print(f\"Number of queries with no passage: {num_missing}\")\n",
    "\n",
    "# Step 4: Encode unique_passages and index with FAISS\n",
    "batch_size = 64\n",
    "passage_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(unique_passages), batch_size), desc=\"Encoding Passages\"):\n",
    "    batch_passages = unique_passages[i:i+batch_size]\n",
    "    batch_dict = tokenizer(\n",
    "        batch_passages,\n",
    "        max_length=512,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "    passage_embeddings.append(embeddings)\n",
    "\n",
    "passage_embeddings = np.vstack(passage_embeddings)\n",
    "print(f\"Passage Embeddings Shape: {passage_embeddings.shape}\")  # (20367, embedding_dim)\n",
    "\n",
    "embedding_dim = passage_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "index.add(passage_embeddings)\n",
    "print(f\"Number of Passages Indexed: {index.ntotal}\")  # 20,367\n",
    "\n",
    "# Step 5: Encode unique_queries\n",
    "query_batch_size = 64\n",
    "query_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(unique_queries), query_batch_size), desc=\"Encoding Queries\"):\n",
    "    batch_queries = unique_queries[i:i+query_batch_size]\n",
    "    batch_dict = tokenizer(\n",
    "        batch_queries,\n",
    "        max_length=512,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "    query_embeddings.append(embeddings)\n",
    "\n",
    "query_embeddings = np.vstack(query_embeddings)\n",
    "print(f\"Query Embeddings Shape: {query_embeddings.shape}\")  # (21222, embedding_dim)\n",
    "\n",
    "# Step 6: Perform Retrieval\n",
    "top_k = 5\n",
    "distances, indices = index.search(query_embeddings, top_k)\n",
    "print(f\"Distances Shape: {distances.shape}\")  # (21222, 5)\n",
    "print(f\"Indices Shape: {indices.shape}\")      # (21222, 5)\n",
    "\n",
    "# Step 7: Evaluate Retrieval Performance\n",
    "# query_to_unique_p_idx: list of length 21222, each entry is the index of the relevant passage\n",
    "# in unique_passages (0 to 20366)\n",
    "\n",
    "hits = 0\n",
    "for i in range(len(unique_queries)):\n",
    "    relevant_idx = query_to_unique_p_idx[i]\n",
    "    if relevant_idx == -1:\n",
    "        continue  # Skip if no relevant passage\n",
    "    if relevant_idx in indices[i]:\n",
    "        hits += 1\n",
    "\n",
    "recall_at_k = hits / len(unique_queries)\n",
    "print(f\"Recall@{top_k}: {recall_at_k * 100:.2f}%\")\n",
    "\n",
    "# Calculate Mean Reciprocal Rank (MRR)\n",
    "mrr_total = 0.0\n",
    "for i in range(len(unique_queries)):\n",
    "    relevant_idx = query_to_unique_p_idx[i]\n",
    "    if relevant_idx == -1:\n",
    "        continue  # Skip if no relevant passage\n",
    "    try:\n",
    "        rank = np.where(indices[i] == relevant_idx)[0][0] + 1  # 1-based rank\n",
    "        mrr_total += 1.0 / rank\n",
    "    except IndexError:\n",
    "        pass  # Relevant passage not in top_k\n",
    "\n",
    "mrr = mrr_total / len(unique_queries)\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr:.4f}\")\n",
    "\n",
    "# Step 8: Display Sample Retrievals\n",
    "passage_idx_to_text = {idx: text for idx, text in enumerate(unique_passages)}\n",
    "\n",
    "num_samples = 5  # Adjust as needed\n",
    "for i in range(num_samples):\n",
    "    query = unique_queries[i][7:]  # Remove 'query: ' prefix\n",
    "    print(f\"\\nQuery {i+1}: {query}\")\n",
    "    print(\"Top Passages:\")\n",
    "    for rank in range(top_k):\n",
    "        passage_idx = indices[i][rank]\n",
    "        similarity_score = distances[i][rank]\n",
    "        passage = unique_passages[passage_idx][9:]  # Remove 'passage: ' prefix\n",
    "        print(f\"  Rank {rank+1}:\")\n",
    "        print(f\"    Similarity Score: {similarity_score:.4f}\")\n",
    "        print(f\"    Passage: {passage}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b30be-7970-44af-a13b-977a5e402f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Perform Retrieval\n",
    "top_k = 5\n",
    "distances, indices = index.search(query_embeddings, top_k)\n",
    "print(f\"Distances Shape: {distances.shape}\")\n",
    "print(f\"Indices Shape: {indices.shape}\")\n",
    "\n",
    "# Step 4: Display Sample Retrievals\n",
    "passage_idx_to_text = {idx: text for idx, text in enumerate(passages)}\n",
    "\n",
    "num_samples = 5  # Adjust as needed\n",
    "for i in range(num_samples):\n",
    "    query = queries[i][7:]  # Remove 'query: ' prefix\n",
    "    print(f\"\\nQuery {i+1}: {query}\")\n",
    "    print(\"Top Passages:\")\n",
    "    for rank in range(top_k):\n",
    "        passage_idx = indices[i][rank]\n",
    "        similarity_score = distances[i][rank]\n",
    "        passage = passages[passage_idx][9:]  # Remove 'passage: ' prefix\n",
    "        print(f\"  Rank {rank+1}:\")\n",
    "        print(f\"    Similarity Score: {similarity_score:.4f}\")\n",
    "        print(f\"    Passage: {passage}\\n\")\n",
    "\n",
    "# (Optional) Step 5: Evaluate Retrieval Performance\n",
    "# Assuming each query i is relevant to passage i\n",
    "relevant_indices = np.arange(len(queries))  # Modify based on actual ground truth\n",
    "\n",
    "hits = 0\n",
    "for i in range(len(queries)):\n",
    "    if relevant_indices[i] in indices[i]:\n",
    "        hits += 1\n",
    "\n",
    "recall_at_k = hits / len(queries)\n",
    "print(f\"Recall@{top_k}: {recall_at_k * 100:.2f}%\")\n",
    "\n",
    "# Calculate Mean Reciprocal Rank (MRR)\n",
    "mrr_total = 0.0\n",
    "for i in range(len(queries)):\n",
    "    try:\n",
    "        rank = np.where(indices[i] == relevant_indices[i])[0][0] + 1  # 1-based rank\n",
    "        mrr_total += 1.0 / rank\n",
    "    except IndexError:\n",
    "        pass  # Relevant passage not in top_k\n",
    "\n",
    "mrr = mrr_total / len(queries)\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99ba7bf9-3225-43f0-906f-56b19ca522f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import Tensor\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# def average_pool(last_hidden_states: Tensor,\n",
    "#                  attention_mask: Tensor) -> Tensor:\n",
    "#     last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "#     return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "# # Set the device (GPU if available, else CPU)\n",
    "# device = torch.device('cuda:1')\n",
    "# print(f'Using device: {device}')\n",
    "\n",
    "# # Each input text should start with \"query: \" or \"passage: \", even for non-English texts.\n",
    "# # For tasks other than retrieval, you can simply use the \"query: \" prefix.\n",
    "# input_texts = input_t\n",
    "\n",
    "# # Load tokenizer and model\n",
    "# tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "# model = AutoModel.from_pretrained('intfloat/multilingual-e5-large')\n",
    "\n",
    "# # Move the model to the GPU (if available)\n",
    "# model.to(device)\n",
    "\n",
    "# # Tokenize the input texts\n",
    "# batch_dict = tokenizer(\n",
    "#     input_texts,\n",
    "#     max_length=512,\n",
    "#     padding=True,\n",
    "#     truncation=True,\n",
    "#     return_tensors='pt'\n",
    "# )\n",
    "\n",
    "# # Move the input tensors to the GPU (if available)\n",
    "# batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
    "\n",
    "# # Disable gradient calculation for inference\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**batch_dict)\n",
    "\n",
    "# # Compute embeddings using average pooling\n",
    "# embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "# # Normalize embeddings\n",
    "# embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "# # Compute similarity scores\n",
    "# scores = (embeddings[:2] @ embeddings[2:].T) * 100\n",
    "# print(scores.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "167bd135-2c47-44dd-8a26-62fb58a3ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch import Tensor\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# from tqdm import tqdm\n",
    "# import faiss\n",
    "# import numpy as np\n",
    "\n",
    "# def average_pool(last_hidden_states: Tensor,\n",
    "#                  attention_mask: Tensor) -> Tensor:\n",
    "#     last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "#     return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "# # Set the device (adjust 'cuda:3' based on your setup)\n",
    "# device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f'Using device: {device}')\n",
    "\n",
    "# # Load tokenizer and model\n",
    "# tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "# model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to(device)\n",
    "\n",
    "# # Assuming 'queries' and 'passages' lists are already defined and populated\n",
    "# # queries = ['query: ...', 'query: ...', ..., 'query: ...']  # 21,223 entries\n",
    "# # passages = ['passage: ...', 'passage: ...', ..., 'passage: ...']  # 21,223 entries\n",
    "\n",
    "# print(f\"Number of Queries: {len(queries)}\")\n",
    "# print(f\"Number of Passages: {len(passages)}\")\n",
    "\n",
    "# # Step 1: Encode and Index Passages\n",
    "# batch_size = 64\n",
    "# passage_embeddings = []\n",
    "\n",
    "# for i in tqdm(range(0, len(passages), batch_size), desc=\"Encoding Passages\"):\n",
    "#     batch_passages = passages[i:i+batch_size]\n",
    "#     batch_dict = tokenizer(\n",
    "#         batch_passages,\n",
    "#         max_length=512,\n",
    "#         padding=True,\n",
    "#         truncation=True,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "#     batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**batch_dict)\n",
    "    \n",
    "#     embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "#     embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "#     embeddings = embeddings.cpu().numpy()\n",
    "#     passage_embeddings.append(embeddings)\n",
    "\n",
    "# passage_embeddings = np.vstack(passage_embeddings)\n",
    "# print(f\"Passage Embeddings Shape: {passage_embeddings.shape}\")\n",
    "\n",
    "# embedding_dim = passage_embeddings.shape[1]\n",
    "# index = faiss.IndexFlatIP(embedding_dim)\n",
    "# index.add(passage_embeddings)\n",
    "# print(f\"Number of Passages Indexed: {index.ntotal}\")\n",
    "\n",
    "# # Step 2: Encode Queries\n",
    "# query_batch_size = 64\n",
    "# query_embeddings = []\n",
    "\n",
    "# for i in tqdm(range(0, len(queries), query_batch_size), desc=\"Encoding Queries\"):\n",
    "#     batch_queries = queries[i:i+query_batch_size]\n",
    "#     batch_dict = tokenizer(\n",
    "#         batch_queries,\n",
    "#         max_length=512,\n",
    "#         padding=True,\n",
    "#         truncation=True,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "#     batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**batch_dict)\n",
    "    \n",
    "#     embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "#     embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "#     embeddings = embeddings.cpu().numpy()\n",
    "#     query_embeddings.append(embeddings)\n",
    "\n",
    "# query_embeddings = np.vstack(query_embeddings)\n",
    "# print(f\"Query Embeddings Shape: {query_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39c0dc3c-4550-4bf5-b6c4-b0e21ccfa1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3: Perform Retrieval\n",
    "# top_k = 10\n",
    "# distances, indices = index.search(query_embeddings, top_k)\n",
    "\n",
    "# print(f\"Distances Shape: {distances.shape}\")\n",
    "# print(f\"Indices Shape: {indices.shape}\")\n",
    "\n",
    "# # Step 4: Display Sample Retrievals\n",
    "# num_samples = 1  # Adjust as needed\n",
    "# for i in range(num_samples):\n",
    "#     query = queries[i][7:]  # Remove 'query: ' prefix\n",
    "#     print(f\"\\nQuery {i+1}: {query}\")\n",
    "#     print(\"Top Passages:\")\n",
    "#     for rank in range(top_k):\n",
    "#         passage_idx = indices[i][rank]\n",
    "#         similarity_score = distances[i][rank]\n",
    "#         passage = passages[passage_idx][9:]  # Remove 'passage: ' prefix\n",
    "#         print(f\"  Rank {rank+1}:\")\n",
    "#         print(f\"    Similarity Score: {similarity_score:.4f}\")\n",
    "#         print(f\"    Passage: {passage}\\n\")\n",
    "\n",
    "# # (Optional) Step 5: Evaluate Retrieval Performance\n",
    "# # Assuming each query i is relevant to passage i\n",
    "# relevant_indices = np.arange(len(queries))  # Adjust based on actual ground truth\n",
    "\n",
    "# hits = 0\n",
    "# for i in range(len(queries)):\n",
    "#     if relevant_indices[i] in indices[i]:\n",
    "#         hits += 1\n",
    "\n",
    "# recall_at_k = hits / len(queries)\n",
    "# print(f\"Recall@{top_k}: {recall_at_k * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d853cf-566a-42ca-8f6d-6617727fed2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68738471-618c-4970-ba16-3db2b0e19e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
